{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a642fbd-4ffa-4d4f-999e-402d045026cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b5a4ae7-01f5-4c9e-a4cf-2563706b7df2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../setup/00_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8eb16ed-f57a-45d1-9cd9-66ceecd882c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "import mlflow\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import json \n",
    "import tempfile\n",
    "\n",
    "os.environ['HF_DATASETS_CACHE'] = cifar_cache\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Display environment information\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9744bdd-96e9-46f8-8b15-36a67b37641e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 1,  # Reduced for demonstration\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"num_classes\": 10,\n",
    "    \"save_every\": 1,\n",
    "    \"experiment_name\": \"resnet50_cifar10\"\n",
    "}\n",
    "\n",
    "# CIFAR-10 classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Set up MLflow - only on the main process\n",
    "def is_main_process():\n",
    "    \"\"\"Check if this is the main process (rank 0)\"\"\"\n",
    "    # For Accelerate\n",
    "    if hasattr(accelerator, \"is_main_process\"):\n",
    "        return accelerator.is_main_process\n",
    "    # For distributed training with torch.distributed\n",
    "    if torch.distributed.is_initialized():\n",
    "        return torch.distributed.get_rank() == 0\n",
    "    # Default case (not distributed)\n",
    "    return True\n",
    "\n",
    "# Initialize accelerator first to access its properties\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# # Set up MLflow only on the main process\n",
    "# if is_main_process():\n",
    "#     mlflow.set_experiment(experiment_path)\n",
    "#     print(f\"MLflow experiment set to: {experiment_path}\")\n",
    "# else:\n",
    "#     print(\"This is not the main process. MLflow logging will be disabled.\")\n",
    "\n",
    "# # Save the run id\n",
    "# run_id = None\n",
    "\n",
    "# if is_main_process():\n",
    "#     mlflow_run = mlflow.start_run()\n",
    "#     run_id = mlflow_run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9900a1d-5f3e-4583-85a5-69ef03fbbe83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9655ab60-49a2-4823-8417-df9bf13f31c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7edac5f6-55c0-4dda-bb43-bcc93a386fd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Splits\n",
    "\n",
    "#### Total Rows: 60000\n",
    "\n",
    "\n",
    "| Split       | # of examples |\n",
    "|-------------|---------------|\n",
    "| Train       | 50,000    |\n",
    "| Validation  | 10,000       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd9f311-b31f-422c-a79f-940ae5c6408a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from utils import hf_dataset_utilities as hf_util\n",
    "\n",
    "cifar_dataset = hf_util.hfds_download_volume(\n",
    "  hf_cache = os.environ['HF_DATASETS_CACHE'],\n",
    "  dataset_path= 'uoft-cs/cifar10',\n",
    "  trust_remote_code = True, \n",
    "  disable_progress = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dbd2edb-8d9c-4696-80a6-c4352f6575e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CIFARDataset = hf_util.create_torch_image_dataset(\n",
    "  image_key=\"img\",\n",
    "  label_key=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33600d5-8be3-47cb-904f-ef7db6fbb5c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ds_train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "ds_test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36a5954e-b309-4188-ab37-93968bae1c91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CIFARDataset(cifar_dataset['train'], transform=ds_train_transforms)\n",
    "test_dataset = CIFARDataset(cifar_dataset['test'], transform=ds_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98e11898-1f2e-40fb-a967-8a7367394e39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_cores = spark.sparkContext.defaultParallelism\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5458447a-b98a-4c09-86e5-b1ac6c843ad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Update your number of workers for proper subprocess count (spark executor instances may not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96aac6aa-0bd5-4593-86e2-13bab4d07603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# num_executors = int(spark.sparkContext.getConf().get(\"spark.executor.instances\", \"1\"))\n",
    "num_executors = 2\n",
    "\n",
    "num_workers = int(num_cores/num_executors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07b6b4eb-3c19-4b15-ac69-e482c5afde4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=num_workers, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=num_workers, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d448ba66-b1a1-4149-ac4e-2d04e97e77c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display some sample images\n",
    "def show_images(dataset, num_images=5):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        img, label = dataset[i]\n",
    "        # Denormalize the image\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "        std = np.array([0.2023, 0.1994, 0.2010])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{classes[label]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbe5a69-c58a-44ca-bd93-ba2941025732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Initializing ResNet50 model...\")\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# We create the final linear layer for the classification \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, config[\"num_classes\"])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=config[\"learning_rate\"], \n",
    "    weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config[\"num_epochs\"])\n",
    "\n",
    "# Enable MLflow autologging for PyTorch only on the main process\n",
    "if is_main_process():\n",
    "    mlflow.pytorch.autolog(log_models=True, log_every_n_epoch=1)\n",
    "\n",
    "# Configure accelerator with MLflow tracking, but make it log only from the main process\n",
    "accelerator = Accelerator(log_with=\"mlflow\" if is_main_process() else None)\n",
    "\n",
    "# Check if run_id exists, if not set to None\n",
    "run_id = mlflow.active_run().info.run_id if mlflow.active_run() else None\n",
    "\n",
    "# Initialize trackers only on the main process (experiment path from setup run)\n",
    "if is_main_process() and not run_id:\n",
    "    accelerator.init_trackers(experiment_path, config=config)\n",
    "\n",
    "model, optimizer, train_loader, test_loader, scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_loader, test_loader, scheduler\n",
    ")\n",
    "\n",
    "print(\"Model and training environment prepared!\")\n",
    "print(f\"Using {accelerator.num_processes} GPU(s)\")\n",
    "print(f\"This process has rank: {accelerator.process_index}\")\n",
    "print(f\"Is main process: {accelerator.is_main_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f45f228-1ecd-4cc6-86d2-afc9547ac461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_id = mlflow.active_run().info.run_id if mlflow.active_run() else None\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d21a0c3-350a-4cab-8815-3f3889b0fbf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_model(run_id=None):\n",
    "    \"\"\"\n",
    "    Train the model and log artifacts with MLflow\n",
    "    \n",
    "    Args:\n",
    "        run_id (str, optional): Existing MLflow run ID to continue tracking.\n",
    "                               If None, a new run will be created.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (history dict, mlflow run_id)\n",
    "    \"\"\"\n",
    "    # Training loop\n",
    "    print(\"Starting training...\")\n",
    "    best_accuracy = 0.0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'test_loss': [], 'test_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    # Start or resume an MLflow run only on the main process\n",
    "    if accelerator.is_main_process:\n",
    "        if run_id:\n",
    "            # Log model parameters (only for new runs)\n",
    "            mlflow.log_params({\n",
    "                \"model_type\": \"ResNet50\",\n",
    "                \"batch_size\": config[\"batch_size\"],\n",
    "                \"epochs\": config[\"num_epochs\"],\n",
    "                \"learning_rate\": config[\"learning_rate\"],\n",
    "                \"weight_decay\": config[\"weight_decay\"],\n",
    "                \"optimizer\": \"Adam\",\n",
    "                \"scheduler\": \"CosineAnnealingLR\",\n",
    "                \"num_gpus\": accelerator.num_processes\n",
    "            })\n",
    "            print(f\"Resuming MLflow run with ID: {run_id}\")\n",
    "        else:\n",
    "            # Start new run\n",
    "            mlflow_run = mlflow.start_run()\n",
    "            run_id = mlflow_run.info.run_id\n",
    "            \n",
    "            # Log model parameters (only for new runs)\n",
    "            mlflow.log_params({\n",
    "                \"model_type\": \"ResNet50\",\n",
    "                \"batch_size\": config[\"batch_size\"],\n",
    "                \"epochs\": config[\"num_epochs\"],\n",
    "                \"learning_rate\": config[\"learning_rate\"],\n",
    "                \"weight_decay\": config[\"weight_decay\"],\n",
    "                \"optimizer\": \"Adam\",\n",
    "                \"scheduler\": \"CosineAnnealingLR\",\n",
    "                \"num_gpus\": accelerator.num_processes\n",
    "            })\n",
    "            \n",
    "            print(f\"New MLflow run started with ID: {run_id}\")\n",
    "    \n",
    "    # Make sure all processes are synced\n",
    "    if accelerator.num_processes > 1:\n",
    "        torch.distributed.barrier()\n",
    "    \n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "        for inputs, targets in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': train_loss / (progress_bar.n + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "        \n",
    "        # Gather metrics from all processes\n",
    "        train_loss = accelerator.gather(torch.tensor(train_loss).to(accelerator.device)).sum().item()\n",
    "        total = accelerator.gather(torch.tensor(total).to(accelerator.device)).sum().item()\n",
    "        correct = accelerator.gather(torch.tensor(correct).to(accelerator.device)).sum().item()\n",
    "        \n",
    "        train_accuracy = 100. * correct / total\n",
    "        train_loss = train_loss / len(train_loader.dataset) * accelerator.num_processes\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Gather test metrics from all processes\n",
    "        test_loss = accelerator.gather(torch.tensor(test_loss).to(accelerator.device)).sum().item()\n",
    "        total = accelerator.gather(torch.tensor(total).to(accelerator.device)).sum().item()\n",
    "        correct = accelerator.gather(torch.tensor(correct).to(accelerator.device)).sum().item()\n",
    "        \n",
    "        test_accuracy = 100. * correct / total\n",
    "        test_loss = test_loss / len(test_loader.dataset) * accelerator.num_processes\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Store history (only on main process to avoid duplicates)\n",
    "        if accelerator.is_main_process:\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_accuracy)\n",
    "            history['test_loss'].append(test_loss)\n",
    "            history['test_acc'].append(test_accuracy)\n",
    "            history['lr'].append(current_lr)\n",
    "        \n",
    "            # Log metrics with MLflow\n",
    "            mlflow.log_metrics({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"test_loss\": test_loss,\n",
    "                \"test_accuracy\": test_accuracy,\n",
    "                \"learning_rate\": current_lr\n",
    "            }, step=epoch)\n",
    "        \n",
    "        # Log with accelerator (it handles the main process check internally)\n",
    "        accelerator.log({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"learning_rate\": current_lr\n",
    "        })\n",
    "        \n",
    "        # Print progress (from all processes for debugging, but could limit to main)\n",
    "        print(f\"[Rank {accelerator.process_index}] Epoch {epoch+1}/{config['num_epochs']} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Train Acc: {train_accuracy:.2f}%, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, \"\n",
    "              f\"Test Acc: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        # Make sure all processes are synced before saving checkpoints\n",
    "        if accelerator.num_processes > 1:\n",
    "            torch.distributed.barrier()\n",
    "        \n",
    "        # Save checkpoint using MLflow (only on main process)\n",
    "        if accelerator.is_main_process and ((epoch + 1) % config[\"save_every\"] == 0 or epoch == config[\"num_epochs\"] - 1):\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            \n",
    "            # In Databricks, you can directly log the model without temporary files\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': unwrapped_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'test_accuracy': test_accuracy,\n",
    "            }\n",
    "            \n",
    "            # Log directly to MLflow in Databricks\n",
    "            mlflow.pytorch.log_state_dict(checkpoint, f\"checkpoints/epoch_{epoch+1}\")\n",
    "            print(f\"Checkpoint saved to MLflow run {run_id}, epoch {epoch+1}\")\n",
    "        \n",
    "        \n",
    "        # Save best model using MLflow (only on main process)\n",
    "        if accelerator.is_main_process and test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            \n",
    "            # Log best model directly to MLflow in Databricks\n",
    "            mlflow.pytorch.log_model(\n",
    "                unwrapped_model, \n",
    "                \"best_model\"\n",
    "            )\n",
    "            \n",
    "            # Also log model metadata\n",
    "            model_info = {\n",
    "                'epoch': epoch + 1,\n",
    "                'test_accuracy': test_accuracy,\n",
    "                'config': config,\n",
    "                'classes': classes\n",
    "            }\n",
    "            mlflow.log_dict(model_info, \"best_model/metadata.json\")\n",
    "            \n",
    "            print(f\"New best model saved with accuracy: {best_accuracy:.2f}%\")\n",
    "    \n",
    "    # End the MLflow run (only on main process)\n",
    "    if accelerator.is_main_process:\n",
    "        # Log the final history directly as a dictionary\n",
    "        mlflow.log_dict(history, \"training_history.json\")\n",
    "        print(f\"Training completed. Best accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "    # End training\n",
    "    accelerator.end_training()\n",
    "    \n",
    "    # Make sure all processes are synced before returning\n",
    "    if accelerator.num_processes > 1:\n",
    "        torch.distributed.barrier()\n",
    "    \n",
    "    # Broadcast run_id from rank 0 to all processes\n",
    "    if accelerator.num_processes > 1:\n",
    "        if accelerator.is_main_process:\n",
    "            run_id_tensor = torch.tensor([ord(c) for c in run_id], dtype=torch.long, device=accelerator.device)\n",
    "            run_id_length = torch.tensor([len(run_id)], dtype=torch.long, device=accelerator.device)\n",
    "        else:\n",
    "            run_id_tensor = torch.zeros(100, dtype=torch.long, device=accelerator.device)  # Assume max length 100\n",
    "            run_id_length = torch.zeros(1, dtype=torch.long, device=accelerator.device)\n",
    "        \n",
    "        # Broadcast length first\n",
    "        torch.distributed.broadcast(run_id_length, src=0)\n",
    "        # Then broadcast the actual run_id\n",
    "        torch.distributed.broadcast(run_id_tensor[:run_id_length.item()], src=0)\n",
    "        \n",
    "        if not accelerator.is_main_process:\n",
    "            run_id = ''.join([chr(i) for i in run_id_tensor[:run_id_length.item()].cpu().numpy()])\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        # Log the final history directly as a dictionary\n",
    "        mlflow.end_run()\n",
    "    \n",
    "    # Return the history and run_id to all processes\n",
    "    return history, run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67e4563c-7286-4734-a279-48a612591ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run the training process\n",
    "history, run_id = train_model(run_id)\n",
    "\n",
    "print(f\"MLflow run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e790d33-fcfb-4678-a8f5-ffffcb4805de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Set the registry URI to ensure correct path resolution\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Load the model using the run_id\n",
    "model_uri = f\"runs:/{run_id}/best_model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "# Display the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2308e5d1-f82a-4351-996f-d8572ee20bc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get one image from the test set\n",
    "test_iter = iter(test_loader)\n",
    "images, labels = next(test_iter)  # Use next() function\n",
    "image = images[0].unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "# Display the image and the prediction\n",
    "plt.imshow(image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "plt.title(f\"Predicted: {predicted.item()}, Actual: {labels[0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6bf2d4a-a8bd-4f28-9f19-37c660dded26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Clear GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9728c29-5cdb-4b43-ab8f-1297f9bdfe4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3782954018096600,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "01_cifar_accelerate",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
