{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d51501f2-faaf-49cd-8be8-dc915fc48388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### https://docs.ray.io/en/latest/cluster/vms/user-guides/community/spark.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2b187c5-4dbb-49e0-86a0-44b6d47dc44b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Config:\n",
    "- 2 Workers: 448 GB Memory, 24 Cores\n",
    "  - 2 GPUs per Worker: V100\n",
    "- 1 Driver: 224 GB Memory, 12 Cores\n",
    "Runtime:\n",
    "- 15.4.x-gpu-ml-scala2.12\n",
    "Type:\n",
    "- Standard_NC12s_v3\n",
    "\n",
    "- Cost: 30 DBUs/h + Provider Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a642fbd-4ffa-4d4f-999e-402d045026cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Notes: \n",
    "\n",
    "- We recommend setting the argument num_cpus_worker_node to the number of CPU cores per Apache Spark worker node. Similarly, setting num_gpus_worker_node to the number of GPUs per Apache Spark worker node is optimal. With this configuration, each Apache Spark worker node launches one Ray worker node that will fully utilize the resources of each Apache Spark worker node.\n",
    "- Set the environment variable RAY_memory_monitor_refresh_ms to 0 within the Databricks cluster configuration when starting your Apache Spark cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5935ee48-e128-4a5b-bf8c-b590d24291a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "- In each spark worker node, we recommend making the sum of 'spark_executor_memory + num_Ray_worker_nodes_per_spark_worker * (memory_worker_node + object_store_memory_worker_node)' to be less than 'spark_worker_physical_memory * 0.8', otherwise it might lead to spark worker physical memory exhaustion and Ray task OOM errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf157f83-65a5-4f04-a1d4-b931e74474d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install gym torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6505263-fa16-4759-9f8d-813d5ee46273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d6054fd-fed1-4657-8706-fddb751d45d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15beac95-f356-4616-8975-894d44bd69a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We recommend setting the argument num_cpus_worker_node to the number of CPU cores per Apache Spark worker node. Similarly, setting num_gpus_worker_node to the number of GPUs per Apache Spark worker node is optimal. With this configuration, each Apache Spark worker node launches one Ray worker node that will fully utilize the resources of each Apache Spark worker node.\n",
    "\n",
    "Set the environment variable RAY_memory_monitor_refresh_ms to 0 within the Databricks cluster configuration when starting your Apache Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24b9096a-79c4-422a-b8e9-dfe00a6d88ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# You configured 'spark.task.resource.gpu.amount' to 1.0, we recommend setting this value to 0 so that Spark jobs do not reserve GPU resources, preventing Ray-on-Spark workloads from having the maximum number of GPUs available. In each spark worker node, we recommend making the sum of 'spark_executor_memory + num_Ray_worker_nodes_per_spark_worker * (memory_worker_node + object_store_memory_worker_node)' to be less than 'spark_worker_physical_memory * 0.8', otherwise it might lead to spark worker physical memory exhaustion and Ray task OOM errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "460b42d6-8d54-4c49-bbcd-85f6dd3f0708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "spark.conf.set(\"spark.task.resource.gpu.amount\", \"0\")\n",
    "os.environ[\"RAY_memory_monitor_refresh_ms\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57035b8a-c596-43db-86ff-42acf675a1d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.utils.databricks_utils import get_databricks_env_vars\n",
    "import mlflow \n",
    "\n",
    "mlflow_db_creds = get_databricks_env_vars(\"databricks\")\n",
    "\n",
    "username = \"will.smith@databricks.com\" \n",
    "experiment_name = f\"/Users/{username}/ray_dqn\"\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3952cc1-8850-46c1-b007-b5e3220d6a1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.util.spark import setup_ray_cluster, shutdown_ray_cluster\n",
    "import os \n",
    "\n",
    "# Call before setup_ray_cluster\n",
    "os.environ[\"DATABRICKS_HOST\"] = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = dbutils.secrets.get(scope=\"william_smith_secrets\", key=\"WS_PAT\")\n",
    "\n",
    "setup_ray_cluster(\n",
    "  max_worker_nodes=1,\n",
    "  num_cpus_per_node=12,\n",
    "  num_gpus_per_node=2,\n",
    "  num_cpus_head_node=12,\n",
    "  num_gpus_head_node=2,\n",
    "  collect_log_to_path=\"/dbfs/tmp/ws_ray_collected_logs\"\n",
    ")\n",
    "\n",
    "# Pass any custom Ray configuration with ray.init\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ea251ec-58ff-48d7-8f9a-bbf28a2f628a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Neural network model for approximating Q-values\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "def train_func():\n",
    "    # Function to choose action using epsilon-greedy policy\n",
    "    def select_action(state, epsilon):\n",
    "        if random.random() < epsilon:\n",
    "            return env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            state = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = policy_net(state)\n",
    "            return torch.argmax(q_values).item()  # Exploit\n",
    "\n",
    "    # Function to optimize the model using experience replay\n",
    "    def optimize_model():\n",
    "        if len(memory) < batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = random.sample(memory, batch_size)\n",
    "        state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*batch)\n",
    "\n",
    "        state_batch = torch.FloatTensor(state_batch)\n",
    "        action_batch = torch.LongTensor(action_batch).unsqueeze(1)\n",
    "        reward_batch = torch.FloatTensor(reward_batch)\n",
    "        next_state_batch = torch.FloatTensor(next_state_batch)\n",
    "        done_batch = torch.FloatTensor(done_batch)\n",
    "\n",
    "        # Compute Q-values for current states\n",
    "        q_values = policy_net(state_batch).gather(1, action_batch).squeeze()\n",
    "\n",
    "        # Compute target Q-values using the target network\n",
    "        with torch.no_grad():\n",
    "            max_next_q_values = target_net(next_state_batch).max(1)[0]\n",
    "            target_q_values = reward_batch + gamma * max_next_q_values * (1 - done_batch)\n",
    "\n",
    "        loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    gamma = 0.99\n",
    "    epsilon = 1.0\n",
    "    epsilon_min = 0.01\n",
    "    epsilon_decay = 0.995\n",
    "    batch_size = 64\n",
    "    target_update_freq = 1000\n",
    "    memory_size = 10000\n",
    "    episodes = 1000\n",
    "\n",
    "    # Initialize Q-networks\n",
    "    input_dim = env.observation_space.shape[0]\n",
    "    output_dim = env.action_space.n\n",
    "    policy_net = DQN(input_dim, output_dim)\n",
    "    target_net = DQN(input_dim, output_dim)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "    terminated = False\n",
    "\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "    memory = deque(maxlen=memory_size)\n",
    "\n",
    "    # Main training loop\n",
    "    rewards_per_episode = []\n",
    "    steps_done = 0\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        while not terminated:\n",
    "            # Select action\n",
    "            action = select_action(state, epsilon)\n",
    "            if(DEBUG):\n",
    "                print(env.step(action))\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "            # Store transition in memory\n",
    "            memory.append((state, action, reward, next_state, terminated))\n",
    "            \n",
    "            # Update state\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            \n",
    "            # Optimize model\n",
    "            optimize_model()\n",
    "\n",
    "            # Update target network periodically\n",
    "            if steps_done % target_update_freq == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "            steps_done += 1\n",
    "\n",
    "        # Decay epsilon\n",
    "        epsilon = max(epsilon_min, epsilon_decay * epsilon)\n",
    "        \n",
    "        rewards_per_episode.append(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10232bbe-11c8-4b30-af1e-ee2e00709060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from ray.train import RunConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "#  [4] Configure scaling and resource requirements.\n",
    "# Use GPU to allow cuda \n",
    "scaling_config = ray.train.ScalingConfig(num_workers=2, use_gpu=True)\n",
    "\n",
    "# Local path (/some/local/path/unique_run_name)\n",
    "run_config = RunConfig(storage_path=\"/dbfs/tmp/ray_ws_logs\", name=\"local\")\n",
    "\n",
    "# [5] Launch distributed training job.\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    # [5a] If running in a multi-node cluster, this is where you\n",
    "    # should configure the run's persistent storage that is accessible\n",
    "    # across all worker nodes.\n",
    "    run_config=run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f87d0e-6aab-4d10-8658-7c5d3c6eb873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow \n",
    "\n",
    "try: \n",
    "  with mlflow.start_run() as run:\n",
    "    results = trainer.fit() \n",
    "  for x in results:\n",
    "    mlflow.log_metric(\"x\", x)\n",
    "except:\n",
    "  results = trainer.fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420af9b9-868f-4c8d-8b74-d5811cb0cce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(results.metrics)     # The metrics reported during training.\n",
    "display(results.checkpoint)  # The latest checkpoint reported during training.\n",
    "display(results.path)        # The path where logs are stored.\n",
    "display(results.error)       # The exception that was raised, if training failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8050191-76d1-40a7-b081-f413b5a2efd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = results.checkpoint\n",
    "\n",
    "if(checkpoint is not None):\n",
    "    with checkpoint.as_directory() as checkpoint_dir:\n",
    "        # Change as needed for different DL frameworks\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint.ckpt\"\n",
    "        # Load the model from the checkpoint\n",
    "        model = DQN.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        # Change the MLflow flavor as needed\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "else:\n",
    "    raise Exception(\"No checkpoint found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4f95e44-5a31-4800-8cf8-a105eb459c9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### When finished, be sure to shut down the ray_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "121a50b5-3f93-4d13-a0af-0aae216e6aa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ray.util.spark.shutdown_ray_cluster()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "single_node_pytorch_DQN_ray",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
