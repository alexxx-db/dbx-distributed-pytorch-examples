{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b6f259a-991a-4403-9490-85cb2edaf748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74b9045e-ee9c-4e3a-aa4f-0b8bd6464ff5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a642fbd-4ffa-4d4f-999e-402d045026cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../setup/00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81eed7e4-cb36-45d7-a970-a1b6d22c6ac6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Splits\n",
    "\n",
    "#### Total Rows: 328,000\n",
    "\n",
    "\n",
    "| Split       | # of examples |\n",
    "|-------------|---------------|\n",
    "| Train       | 100,000  |\n",
    "| Validation  | 10,000  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "150eaaa2-c001-410a-9264-8fac0cdb4d60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(handle=\"awsaf49/coco-2017-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08eb9730-3d52-4962-bd46-2e249113eb60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "dataType='val2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(coco_cache, dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1238ba34-559d-47b6-91a7-d34d6616033e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "   transforms.Resize(256),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    " \n",
    "# Load training dataset\n",
    "train_dataset = datasets.CocoDetection(\n",
    "  root='data/train',\n",
    "  annFile='data/train/annotations/instances_train2017.json',\n",
    "  transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e239c1ec-14f2-4134-bf36-0b59b7592598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load validation dataset\n",
    "# val_dataset = datasets.CocoDetection(root='/Volumes/will_smith/datasets/ms_coco/validation',\n",
    "#                                      annFile='/Volumes/will_smith/datasets/ms_coco/train/annotations/instances_val2017.json',\n",
    "#                                      transform=transform)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aff06636-2b4a-4f35-ab0e-d8fba9e4c9aa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Hyperparameters"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import torchvision.models as models\n",
    "from composer.models import ComposerClassifier\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = \"2ep\"\n",
    "num_class =len(set(train_dataset[\"train\"][\"label\"]))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet_composer = ComposerClassifier(resnet, num_classes=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43cd550d-6e37-403f-8d41-ee482c7c272b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = train_dataset.get('train', None)\n",
    "test_dataset = train_dataset.get('valid', None)\n",
    "\n",
    "# Apply transformations directly to the dataset\n",
    "train_dataset =  Dataset.from_dict({\"image\": train_dataset['image'], \"label\": train_dataset[\"label\"]}).with_format(\"torch\", device=\"cuda\")\n",
    "test_dataset =  Dataset.from_dict({\"image\": test_dataset['image'], \"label\": test_dataset[\"label\"]}).with_format(\"torch\", device=\"cuda\")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f17c0f9d-6512-4105-a213-8ce08e23b1ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from composer.models import ComposerModel\n",
    "\n",
    "class ResNet50(ComposerModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet50()\n",
    "\n",
    "    def forward(self, batch): # batch is the output of the dataloader\n",
    "        # specify how batches are passed through the model\n",
    "        inputs, _ = batch\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def loss(self, outputs, batch):\n",
    "        # pass batches and `forward` outputs to the loss\n",
    "        _, targets = batch\n",
    "        return F.cross_entropy(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1e91e89-ebaa-4755-9970-fcbfd83df579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = datasets.ImageNet(\"data\", train=True, download=True, transform=transform)\n",
    "mnist_dataloader = DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d5db960-6ab6-4742-8b73-042be471013a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from composer import Trainer\n",
    "from composer.algorithms import LabelSmoothing, CutMix, ChannelsLast\n",
    "import torch.optim as optim\n",
    "\n",
    "model = ResNet18()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizers=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    # train_dataloader=train_dataloader,\n",
    "    # eval_dataloader=test_dataloader,\n",
    "    max_duration=num_epochs,\n",
    "    algorithms=[\n",
    "        LabelSmoothing(smoothing=0.1),\n",
    "        CutMix(alpha=1.0),\n",
    "        ChannelsLast(),\n",
    "        ]\n",
    ")\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2818997009422438,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "resnet18_coco",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
